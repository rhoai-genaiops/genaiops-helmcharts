# Llama Stack Operator Instance configuration
MODEL_NAME: "llama32"
MODEL_URL: "http://llama-32-predictor.ai501.svc.cluster.local:8080/v1"

# Distribution configuration
distribution:
  image: "quay.io/rhoai-genaiops/llama-stack-vllm-milvus-fms:rhoai-3.0-fix2" #0.13

# Persistent storage for Milvus and SQLite data (canopy namespace only)
# The operator automatically creates a PVC based on these settings
persistence:
  enabled: true
  size: 10Gi
  mountPath: /opt/app-root/src/data

# ConfigMap for Llama Stack configuration
configMap:
  enabled: true

# Telemetry configuration
telemetry:
  enabled: false

rag:
  enabled: false
  milvus:
    service: "milvus-test"

mcp:
  enabled: false

otelCollector:
  enabled: false

eval:
  enabled: false

guardrails:
  enabled: false
  regex:
    enabled: false
    filter: ["(?i).*fight club.*"]
  hap:
    enabled: false
  prompt_injection:
    enabled: false
  language_detection:
    enabled: false
