sealed_secrets:
  enabled: true
  secretName: whatever
# Llama Stack Operator Instance configuration
models:
  - name: "llama32"
    url: "http://llama-32-predictor.ai501.svc.cluster.local:8080/v1"

# Distribution configuration
distribution:
  image: "quay.io/rhoai-genaiops/llama-stack-vllm-milvus-fms:rhoai-3.0-fix3"


# ConfigMap for Llama Stack configuration
configMap:
  enabled: true

# Telemetry configuration
telemetry:
  enabled: true

rag:
  enabled: false
  milvus:
    service: "milvus-test"

mcp:
  enabled: false

mcp_aihub:
  enabled: false

otelCollector:
  enabled: true

eval:
  enabled: false

guardrails:
  enabled: false
  regex:
    enabled: false
    filter: ["(?i).*fight club.*"]
  hap:
    enabled: false
  prompt_injection:
    enabled: false
  language_detection:
    enabled: false
