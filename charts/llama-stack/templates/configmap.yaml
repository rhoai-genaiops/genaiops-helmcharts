---
apiVersion: v1
kind: ConfigMap
metadata:
  name: run-config
  labels:
    {{- include "llama-stack.labels" . | nindent 4 }}
data:
  config.yaml: |-
    version: '2'
    image_name: remote-vllm
    apis:
    - agents
    - inference
    - tool_runtime
    - safety
    - vector_io
    {{- if .Values.otelCollector.enabled }}
    - telemetry
    {{- end }}
    {{- if .Values.eval.enabled }}
    - eval
    - datasetio
    - scoring
    {{- end }}
    providers:
      inference:
      - provider_id: ${env.MODEL_NAME}
        provider_type: remote::vllm
        config:
          url: ${env.MODEL_URL}/v1
          max_tokens: 8192
          api_token: fake
          tls_verify: false
      agents:
      - provider_id: meta-reference
        provider_type: inline::meta-reference
        config:
          persistence_store:
            type: sqlite
            namespace: null
            db_path: ${env.SQLITE_STORE_DIR:~/.llama/distributions/remote-vllm}/persistence_store.db
          responses_store:
            type: sqlite
            namespace: null
            db_path: ${env.SQLITE_STORE_DIR:~/.llama/distributions/remote-vllm}/responses_store.db
      {{- if .Values.eval.enabled }}
      eval:
      - provider_id: meta-reference
        provider_type: inline::meta-reference
        config:
          kvstore:
            type: sqlite
            namespace: null
            db_path: ${env.SQLITE_STORE_DIR:~/.llama/distributions/remote-vllm}/meta_reference_eval.db
      datasetio:
      - provider_id: huggingface
        provider_type: remote::huggingface
        config:
          kvstore:
            type: sqlite
            namespace: null
            db_path: ${env.SQLITE_STORE_DIR:~/.llama/distributions/remote-vllm}/huggingface_datasetio.db
      - provider_id: localfs
        provider_type: inline::localfs
        config:
          kvstore:
            type: sqlite
            namespace: null
            db_path: ${env.SQLITE_STORE_DIR:~/.llama/distributions/remote-vllm}/localfs_datasetio.db
      scoring:
      - provider_id: basic
        provider_type: inline::basic
        config: {}
      - provider_id: llm-as-judge
        provider_type: inline::llm-as-judge
        config: {}
      {{- end }}
      {{- if .Values.otelCollector.enabled }}
      telemetry:
      - provider_id: meta-reference
        provider_type: inline::meta-reference
        config: {}
      {{- end }}
      {{- if .Values.mcp.enabled }}
      tool_runtime:
      - provider_id: model-context-protocol
        provider_type: remote::model-context-protocol
        config: {}
      {{- end }}
    metadata_store:
      type: sqlite
      db_path: ${env.SQLITE_STORE_DIR:~/.llama/distributions/remote-vllm}/registry.db
      namespace: null
    models:
    - metadata: {}
      model_id: ${env.MODEL_NAME}
      provider_id: ${env.MODEL_NAME}
      model_type: llm
    vector_dbs: []
    datasets: []
    scoring_fns: []
    benchmarks: []
    tool_groups: []
