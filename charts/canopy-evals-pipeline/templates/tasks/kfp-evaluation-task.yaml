apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: kfp-evaluation-task
spec:
  workspaces:
    - name: output
      description: Workspace for pipeline files
  params:
    - name: BASE_URL
      description: Base URL for LlamaStack
      type: string
    - name: BACKEND_URL
      description: Backend URL for canopy
      type: string
    - name: GIT_URL
      type: string
      default: https://github.com/rhoai-genaiops/canopy-evals
      description: Git repository URL
    - name: GIT_BRANCH
      type: string
      default: "main"
      description: Git branch to clone
    - name: GIT_REVISION
      type: string
      default: "latest"
      description: Git revision to clone
    - name: GIT_SHORT_REVISION
      description: Short Git commit hash
      type: string
      default: "latest"
  steps:
  - name: kfp-evaluation-task
    workingDir: $(workspaces.output.path)/test-pipeline
    image: registry.redhat.io/ubi9/python-311:latest
    command: ["/bin/sh", "-c"]
    args:
    - |
      echo "Installing KFP dependencies..."
      python3 -m pip install kfp==2.9.0 kfp.kubernetes==1.3.0
      
      echo "Executing Kubeflow Pipeline..."
      cat << 'EOF' | python3
      import kfp
      import sys
      import os
      
      # Add current directory to Python path
      sys.path.insert(0, '.')
      
      # Import the pipeline
      from kfp_pipeline import canopy_test_pipeline
      
      # Get namespace from service account
      namespace_file_path = '/var/run/secrets/kubernetes.io/serviceaccount/namespace'
      with open(namespace_file_path, 'r') as namespace_file:
          namespace = namespace_file.read()
      
      # Setup KFP client
      kubeflow_endpoint = f'https://ds-pipeline-dspa.{namespace}.svc:8443'
      
      sa_token_file_path = '/var/run/secrets/kubernetes.io/serviceaccount/token'
      with open(sa_token_file_path, 'r') as token_file:
          bearer_token = token_file.read()
      
      ssl_ca_cert = '/var/run/secrets/kubernetes.io/serviceaccount/service-ca.crt'
      
      print(f'Connecting to Data Science Pipelines: {kubeflow_endpoint}')
      client = kfp.Client(
          host=kubeflow_endpoint,
          existing_token=bearer_token,
          ssl_ca_cert=ssl_ca_cert
      )
      
      # Pipeline arguments
      arguments = {
          "repo_url": "$(params.GIT_URL)",
          "branch": "$(params.GIT_BRANCH)",
          "base_url": "$(params.BASE_URL)",
          "backend_url": "$(params.BACKEND_URL)",
          "secret_name": "{{ .Values.secrets.s3.name }}",
          "git_hash": "$(params.GIT_SHORT_REVISION)",
      }

      print(f"Arguments for the pipeline: {arguments}")
      
      print("ðŸƒâ€â™‚ï¸ Starting Kubeflow Pipeline run...")
      run_id = client.create_run_from_pipeline_func(
          canopy_test_pipeline,
          arguments=arguments,
          experiment_name="canopy-evals-pipeline",
          namespace=namespace,
          enable_caching=False
      )

      print("ðŸ¥± wait for the run to finish")
      # wait for the run to finish
      client.wait_for_run_completion(
          run_id=run_id.run_id, 
          timeout=7200,
          sleep_duration=5,
      )

      print(f"ðŸŽ‰ Pipeline run created with ID: {run_id.run_id}")
      print("âœ… Kubeflow Pipeline execution completed successfully!")
      EOF